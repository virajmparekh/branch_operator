{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a BranchOperator in Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airflow's BranchOperator is a great way to execute different workflows based off of a condition.\n",
    "\n",
    "These can be used for safety checks, notifications, or whatever else a particular usecase.\n",
    "\n",
    "At it's core, a BranchOperator is just a PythonOperator that returns the next task to be executed.\n",
    "\n",
    "In the past, Astronomer has used it to make requests to a IP-geolocation API when there has been at least 500 new visits to a website to get around API call restrictions and other such use cases.\n",
    "\n",
    "https://airflow.incubator.apache.org/concepts.html?highlight=branch#branching\n",
    "\n",
    "_This example will show executing a set of steps based on the results of a query._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BranchOperator.\n",
    "\n",
    "Can be used for safety checks or notifications.\n",
    "\n",
    "This was written when we were having issues with the Bing/Google Ads APIs. Lack of data would lead to \n",
    "inaccurate downstream aggregations.\n",
    "\n",
    "Astronomer related logic was taken out and replaced with Dummy tasks.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.python_operator import PythonOperator, BranchPythonOperator\n",
    "from airflow.hooks.postgres_hook import PostgresHook\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2017, 7, 31),\n",
    "    'email': ['viraj@astronomer.io'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=1)\n",
    "}\n",
    "\n",
    "# instantiate dag\n",
    "dag = DAG(dag_id='check_api_runs',\n",
    "          default_args=default_args,\n",
    "          schedule_interval='0 10 * * *')\n",
    "\n",
    "\n",
    "def get_recent_date():\n",
    "    \"\"\"\n",
    "    Python function that grabs the latest date from 3 data sources from internal reporting.\n",
    "    The rest of the DAG does not execute unless each one has successfully run.\n",
    "    \"\"\"\n",
    "\n",
    "    bing_date = PostgresHook('astro_redshift').get_pandas_df(\n",
    "        \"\"\" SELECT max(gregorian_date) FROM dev.aa_bing_ads.conversion;\"\"\")['max'][0]\n",
    "    google_date = PostgresHook('astro_redshift').get_pandas_df(\n",
    "        \"\"\" SELECT max(day) FROM dev.aa_google_adwords.cc_search_query_performance_report\t; \"\"\")['max'][0]\n",
    "    sf_date = PostgresHook('astro_redshift').get_pandas_df(\n",
    "        \"\"\" SELECT max(created_date) FROM aa_salesforce.sf_lead; \"\"\")['max'][0].to_pydatetime().date()\n",
    "    # Salesforce is never easy to work with.\n",
    "    # Makes sense their API is called simple-salesforce in the same way\n",
    "    # the s in SOAP stands for simple.\n",
    "\n",
    "    yesterday = datetime.today().date() - timedelta(1)\n",
    "\n",
    "    if yesterday != (bing_date and google_date and sf_date):\n",
    "        return 'trigger_warning'\n",
    "    return 'kickoff_summary_tables'\n",
    "\n",
    "\n",
    "with dag:\n",
    "    kick_off_dag = DummyOperator(task_id='kick_off_dag')\n",
    "    \n",
    "    branch = BranchPythonOperator(task_id='check_for_data', python_callable=get_recent_date)\n",
    "    \n",
    "    kickoff_summary_tables = DummyOperator(task_id='kickoff_summary_tables')\n",
    "    \n",
    "    # Replace this with the type of warning you want to trigger.\n",
    "    # I.e. slack notification, trigger DAG, etc.\n",
    "    trigger_warning = DummyOperator(task_id='trigger_warning')\n",
    "    \n",
    "    run_condiiton = DummyOperator(task_id = 'sql_statement_one')\n",
    "    downstream_task = DummyOperator(task_id = 'sql_statement_two')\n",
    "    \n",
    "    # Set the dependencies for both possibilities\n",
    "    kick_off_dag >> branch\n",
    "    branch >> kickoff_summary >> run_condition >> downstream_task\n",
    "    branch >> trigger_warning\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![branch_dag](img/branch_operator_dag.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
